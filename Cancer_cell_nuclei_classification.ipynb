{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"#importing  all tyhe necessary libraries\n\nfrom skimage.io import imread #for reading image\nimport numpy as np # linear algebra\nimport pandas as pd # pandas for data processing\nfrom tqdm import tqdm_notebook as tqdm\nfrom sklearn.preprocessing import LabelEncoder\nfrom PIL import Image\nimport matplotlib.pyplot as plt # for plotting the images\nimport torch #for pytorch tensors\n# Neural networks can be constructed using the torch.nn package.\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nfrom torch.utils.data.sampler import SubsetRandomSampler\nfrom torch.utils.data import Dataset\nfrom torch.utils.data import DataLoader\nimport torchvision\nimport torchvision.transforms as transforms\n\nfrom sklearn.model_selection import train_test_split\n# for evaluating the model\n\nfrom sklearn.metrics import accuracy_score #getting accuracy of a model\nfrom tqdm import tqdm\n\n# PyTorch libraries and modules\n\nimport torch\nfrom torch.autograd import Variable\n#importing all kinds of activation function\nfrom torch.nn import Linear, ReLU, CrossEntropyLoss, Sequential, Conv2d, MaxPool2d, Module, Softmax, BatchNorm2d, Dropout\nfrom torch.optim import Adam, SGD\n\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-05-23T16:04:39.167061Z","iopub.execute_input":"2021-05-23T16:04:39.167719Z","iopub.status.idle":"2021-05-23T16:04:43.572195Z","shell.execute_reply.started":"2021-05-23T16:04:39.167584Z","shell.execute_reply":"2021-05-23T16:04:43.570717Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#replacing the type names from string to integer\ndata = pd.read_csv('/kaggle/input/deep-learning-for-msc-coursework-2021/train.csv')\nType = {\"Connective\" : 0,\"Immune\" : 1,\"Cancer\" : 2,\"Normal\" : 3,}\ndata.Type = [Type[item] for item in data.Type]\nprint(data.columns)","metadata":{"execution":{"iopub.status.busy":"2021-05-23T16:04:43.573738Z","iopub.execute_input":"2021-05-23T16:04:43.574027Z","iopub.status.idle":"2021-05-23T16:04:43.606286Z","shell.execute_reply.started":"2021-05-23T16:04:43.573999Z","shell.execute_reply":"2021-05-23T16:04:43.605083Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_img = []\n\nfor img_name in tqdm(data['Id']):\n\n    # give the image path\n\n    image_path = '/kaggle/input/deep-learning-for-msc-coursework-2021/train/train/' + str(img_name) + '.png'\n\n    # read images\n\n    img = imread(image_path)\n    \n    # pixel to float 32\n\n    img = img.astype('float32')\n\n    # normalize the pixel values\n\n    img /= 255.0\n\n    # append the image\n\n    train_img.append(img)\n\n\n\n# convert the list to numpy array\n\ntrain_x = np.array(train_img)\n\n# setting the target\n\ntrain_y = data['Type'].values\n\ntrain_x.shape\n","metadata":{"execution":{"iopub.status.busy":"2021-05-23T16:04:43.608469Z","iopub.execute_input":"2021-05-23T16:04:43.608836Z","iopub.status.idle":"2021-05-23T16:04:58.804512Z","shell.execute_reply.started":"2021-05-23T16:04:43.608798Z","shell.execute_reply":"2021-05-23T16:04:58.803337Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# splitting the images to training and validation\ntrain_x, val_x, train_y, val_y = train_test_split(train_x, train_y, test_size = 0.2)\n(train_x.shape, train_y.shape), (val_x.shape, val_y.shape)\n\n\n\nprint(train_x.shape)\nprint(train_y.shape)\nprint(val_x.shape)\nprint(val_y.shape)\n\n# convert training images into torch tensors\ntrain_x = train_x.reshape(1752, 3, 64, 64) #reshape to cnn format\ntrain_x  = torch.from_numpy(train_x)\n\nval_x = val_x.reshape(438, 3, 64, 64) #reshape to tensor format\nval_x  = torch.from_numpy(val_x)\n\n# convert the target into torch tensor\ntrain_y = train_y.astype(int);\ntrain_y = torch.from_numpy(train_y)\n\nval_y = val_y.astype(int);\nval_y  = torch.from_numpy(val_y)\n\n# shape of training data\ntrain_x.shape, train_y.shape","metadata":{"execution":{"iopub.status.busy":"2021-05-23T16:04:58.806375Z","iopub.execute_input":"2021-05-23T16:04:58.806692Z","iopub.status.idle":"2021-05-23T16:04:58.880289Z","shell.execute_reply.started":"2021-05-23T16:04:58.806660Z","shell.execute_reply":"2021-05-23T16:04:58.878956Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class Net(Module):   #class for the networks\n    def __init__(self):\n        super(Net, self).__init__()\n\n        self.cnn_layers = Sequential(\n            # Define a CNN layer\n            Conv2d(3, 16, kernel_size=3, stride=1, padding=1),\n            BatchNorm2d(16),\n            ReLU(inplace=True),\n            MaxPool2d(kernel_size=2, stride=2),\n            \n            # Define a CNN layer\n            Conv2d(16, 16, kernel_size=3, stride=1, padding=1),\n            BatchNorm2d(16),\n            ReLU(inplace=True),\n            MaxPool2d(kernel_size=2, stride=2),\n            \n            \n        )\n#define linear layer\n        self.linear_layers = Sequential(\n            Linear(4096, 4)\n        )\n\n    # Define forward propagation    \n    def forward(self, x):\n        x = self.cnn_layers(x)\n        \n        x = x.view(x.size(0), -1)\n        \n        x = self.linear_layers(x)\n        return x","metadata":{"execution":{"iopub.status.busy":"2021-05-23T16:04:58.883498Z","iopub.execute_input":"2021-05-23T16:04:58.883882Z","iopub.status.idle":"2021-05-23T16:04:58.893081Z","shell.execute_reply.started":"2021-05-23T16:04:58.883840Z","shell.execute_reply":"2021-05-23T16:04:58.892126Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# define the model\nmodel = Net()\n# define the optimizer\noptimizer = Adam(model.parameters(), lr=0.05)\n# define the loss function\ncriterion = CrossEntropyLoss()\n# check if GPU is available\nif torch.cuda.is_available():\n    model = model.cuda()\n    criterion = criterion.cuda()\n    \nprint(model)","metadata":{"execution":{"iopub.status.busy":"2021-05-23T16:04:58.894659Z","iopub.execute_input":"2021-05-23T16:04:58.894969Z","iopub.status.idle":"2021-05-23T16:04:58.949619Z","shell.execute_reply.started":"2021-05-23T16:04:58.894937Z","shell.execute_reply":"2021-05-23T16:04:58.948021Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def train(epoch):\n    model.train()\n    tr_loss = 0\n    # fetch the training set\n    x_train, y_train = Variable(train_x), Variable(train_y)\n    # fetch the validation set\n    \n    x_val, y_val = Variable(val_x), Variable(val_y)\n    # convert data into GPU format if gpu is available\n    if torch.cuda.is_available():\n        x_train = x_train.cuda()\n        y_train = y_train.cuda()\n        x_val = x_val.cuda()\n        y_val = y_val.cuda()\n\n    # clear previous gradient values\n    optimizer.zero_grad()\n    \n    # predict for training and validation set\n    output_train = model(x_train)\n    output_val = model(x_val)\n\n    # compute training and validation loss\n    loss_train = criterion(output_train, y_train)\n    loss_val = criterion(output_val, y_val)\n    train_losses.append(loss_train)\n    val_losses.append(loss_val)\n\n    # compute updated weights for all model parameters\n    loss_train.backward()\n    optimizer.step()\n    tr_loss = loss_train.item()\n    if epoch%2 == 0:\n        # printing the validation loss\n        print('Epoch : ',epoch+1, '\\t', 'loss :', loss_val)","metadata":{"execution":{"iopub.status.busy":"2021-05-23T16:04:58.951635Z","iopub.execute_input":"2021-05-23T16:04:58.952091Z","iopub.status.idle":"2021-05-23T16:04:58.963741Z","shell.execute_reply.started":"2021-05-23T16:04:58.952043Z","shell.execute_reply":"2021-05-23T16:04:58.961811Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# define the number of epochs\nn_epochs = 32\n# train_losses to store training losses\ntrain_losses = []\n# val_losses to store validation losses\nval_losses = []\n# train the model for n_epoch number of iterations\nfor epoch in range(n_epochs):\n    train(epoch)","metadata":{"execution":{"iopub.status.busy":"2021-05-23T16:04:58.968650Z","iopub.execute_input":"2021-05-23T16:04:58.969179Z","iopub.status.idle":"2021-05-23T16:07:34.290392Z","shell.execute_reply.started":"2021-05-23T16:04:58.969140Z","shell.execute_reply":"2021-05-23T16:07:34.289254Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# predict for training set\nwith torch.no_grad():\n    output = model(train_x)\n    \nsoftmax = torch.exp(output).cpu()\nprob = list(softmax.numpy())\npredictions = np.argmax(prob, axis=1)\n\n# accuracy of training set\naccuracy_score(train_y, predictions)","metadata":{"execution":{"iopub.status.busy":"2021-05-23T16:07:34.292559Z","iopub.execute_input":"2021-05-23T16:07:34.292911Z","iopub.status.idle":"2021-05-23T16:07:36.277690Z","shell.execute_reply.started":"2021-05-23T16:07:34.292875Z","shell.execute_reply":"2021-05-23T16:07:36.276503Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#predict for validation\nwith torch.no_grad():\n    output = model(val_x\n                  )\n\nsoftmax = torch.exp(output).cpu()\nprob = list(softmax.numpy())\npredictions = np.argmax(prob, axis=1)\n\n# accuracy for the validation set\naccuracy_score(val_y, predictions)","metadata":{"execution":{"iopub.status.busy":"2021-05-23T16:07:36.279591Z","iopub.execute_input":"2021-05-23T16:07:36.279940Z","iopub.status.idle":"2021-05-23T16:07:36.767352Z","shell.execute_reply.started":"2021-05-23T16:07:36.279904Z","shell.execute_reply":"2021-05-23T16:07:36.766301Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"list1=[]\nlist2=[]\nfor i in train_losses:\n    list1.append(i.detach().numpy())\n   \nfor  j in val_losses:\n    list2.append(i.detach().numpy())\n   \nplt.plot(list1,label='training loss')\nplt.plot(list2,label='validation loss')\nplt.legend()\nplt.show()\n","metadata":{"execution":{"iopub.status.busy":"2021-05-23T16:07:36.768763Z","iopub.execute_input":"2021-05-23T16:07:36.769109Z","iopub.status.idle":"2021-05-23T16:07:36.983574Z","shell.execute_reply.started":"2021-05-23T16:07:36.769075Z","shell.execute_reply":"2021-05-23T16:07:36.982170Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#to get the final_data which will be used to get the test images\nimport glob\nnamelist=[]\nfinal_data=pd.DataFrame(columns=['Pred'])\ntestdata = glob.glob(\"/kaggle/input/deep-learning-for-msc-coursework-2021/test/test/*.png\")\nfor filename in testdata:\n    #print(filename)\n    name = filename.replace(\"kaggle/input/deep-learning-for-msc-coursework-2021/test/test/\",\"\").replace('.png','')\n    name=name.replace(\"/\",\"\")\n    name=name.strip()\n    ##print(name)\n    namelist.append(int(name))\n#print(namelist)\nfinal_data[\"Id\"]=namelist\nfinal_data.drop(columns=['Pred'],inplace=True)\nfinal_data.head()","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-05-23T16:07:36.985543Z","iopub.execute_input":"2021-05-23T16:07:36.986050Z","iopub.status.idle":"2021-05-23T16:07:37.058869Z","shell.execute_reply.started":"2021-05-23T16:07:36.986000Z","shell.execute_reply":"2021-05-23T16:07:37.057465Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#To get the test_x\ntest_img = []\n\nfor img_name in final_data['Id']:\n\n    # defime the image path\n\n    image_path = '/kaggle/input/deep-learning-for-msc-coursework-2021/test/test/' + str(img_name) + '.png'\n\n    # read the image\n\n    img = imread(image_path)\n    \n    # convert the type of pixel to float 32\n\n    img = img.astype('float32')\n\n    # normalise the pixel values\n\n    img /= 255.0\n\n    # append the image into the list\n\n    test_img.append(img)\n\n\n\n# convert the list to numpy array\n\ntest_x = np.array(test_img)\n\n\ntest_x.shape\n","metadata":{"execution":{"iopub.status.busy":"2021-05-23T16:07:37.060621Z","iopub.execute_input":"2021-05-23T16:07:37.061098Z","iopub.status.idle":"2021-05-23T16:07:39.036558Z","shell.execute_reply.started":"2021-05-23T16:07:37.061054Z","shell.execute_reply":"2021-05-23T16:07:39.035556Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# convert training images into torch format\ntest_x = test_x.reshape(400, 3, 64, 64)\ntest_x  = torch.from_numpy(test_x)\ntest_x.shape","metadata":{"execution":{"iopub.status.busy":"2021-05-23T16:07:39.037804Z","iopub.execute_input":"2021-05-23T16:07:39.038105Z","iopub.status.idle":"2021-05-23T16:07:39.044742Z","shell.execute_reply.started":"2021-05-23T16:07:39.038076Z","shell.execute_reply":"2021-05-23T16:07:39.043823Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# generate predictions for test set\nwith torch.no_grad():\n    output = model(test_x)\n\nsoftmax = torch.exp(output).cpu()\nprob = list(softmax.numpy())\n\npredictions = np.argmax(prob, axis=1)\n\nfinal_data['Type']=predictions\nfinal_data.head()","metadata":{"execution":{"iopub.status.busy":"2021-05-23T16:07:39.046118Z","iopub.execute_input":"2021-05-23T16:07:39.046431Z","iopub.status.idle":"2021-05-23T16:07:39.458470Z","shell.execute_reply.started":"2021-05-23T16:07:39.046402Z","shell.execute_reply":"2021-05-23T16:07:39.457211Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# convert the integers labels back to the string type\nType = {0 : \"Connective\",1 : \"Immune\",2 : \"Cancer\",3 :\"Normal\"}\nfinal_data.Type = [Type[item] for item in final_data.Type]\nprint(final_data)","metadata":{"execution":{"iopub.status.busy":"2021-05-23T16:07:39.460484Z","iopub.execute_input":"2021-05-23T16:07:39.460930Z","iopub.status.idle":"2021-05-23T16:07:39.473217Z","shell.execute_reply.started":"2021-05-23T16:07:39.460881Z","shell.execute_reply":"2021-05-23T16:07:39.471801Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Getting the output to a csv file\nnew_final_data = final_data.sort_values(by = 'Id')\nprint(new_final_data.head())","metadata":{"execution":{"iopub.status.busy":"2021-05-23T16:07:39.474740Z","iopub.execute_input":"2021-05-23T16:07:39.475058Z","iopub.status.idle":"2021-05-23T16:07:39.490220Z","shell.execute_reply.started":"2021-05-23T16:07:39.475030Z","shell.execute_reply":"2021-05-23T16:07:39.488601Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"new_final_data.to_csv(\"test_26.csv\", index = False)","metadata":{"execution":{"iopub.status.busy":"2021-05-23T16:07:39.491848Z","iopub.execute_input":"2021-05-23T16:07:39.492193Z","iopub.status.idle":"2021-05-23T16:07:39.514609Z","shell.execute_reply.started":"2021-05-23T16:07:39.492151Z","shell.execute_reply":"2021-05-23T16:07:39.513130Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}